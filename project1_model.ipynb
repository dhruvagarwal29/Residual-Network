{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKdxyrRaFojC"
      },
      "outputs": [],
      "source": [
        "# importing all the important and reuqired libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# for data augmentation - used RandomHorizontalFlip, RandomCrop, Normalize for train_data \n",
        "# and Normalize for test_data\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=32, padding=[0, 2, 3, 4]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# setting batch size to be 64\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# creating the basic block\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        \n",
        "        # adding drop out, here given p = 0.1 which gave the best results out of [0.1,0.2,0.3,0.4,0.5]\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.dropout(out) \n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "#creating resnet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def project1_model():\n",
        "    # using cuda if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "\n",
        "    # creating the model\n",
        "    net = ResNet(BasicBlock, [1,1,1,1]).to(device)\n",
        "\n",
        "    # defining the loss and optimizer\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "    #declaring our losses\n",
        "    test_loss_history = []\n",
        "    train_loss_history = []\n",
        "    acc_history_train = []\n",
        "    acc_history_test = []\n",
        "\n",
        "    # training and testing for 200 epochs\n",
        "    for epoch in range(200):\n",
        "\n",
        "        train_loss,test_loss = 0.0,0.0\n",
        "        correct_train,correct_test,total_train,total_test = 0,0,0,0\n",
        "\n",
        "        for i, data in enumerate(trainloader):\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predicted_output = net(images)\n",
        "            fit = loss(predicted_output,labels)\n",
        "            fit.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += fit.item()\n",
        "            _, predicted_output = torch.max(predicted_output.data, 1)\n",
        "            correct_train += (predicted_output == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        for i, data in enumerate(testloader):\n",
        "            with torch.no_grad():\n",
        "                images, labels = data\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                predicted_output = net(images)\n",
        "                fit = loss(predicted_output,labels)\n",
        "                test_loss += fit.item() \n",
        "                _, predicted_output = torch.max(predicted_output.data, 1)\n",
        "                correct_test += (predicted_output == labels).sum().item()\n",
        "                total_test += labels.size(0)\n",
        "\n",
        "        train_loss = train_loss/len(trainloader)\n",
        "        test_loss = test_loss/len(testloader)\n",
        "        train_loss_history.append(train_loss)\n",
        "        test_loss_history.append(test_loss)\n",
        "\n",
        "        train_accuracy = (correct_train*100)/total_train\n",
        "        test_accuracy = (correct_test*100)/total_test\n",
        "        acc_history_train.append(train_accuracy)\n",
        "        acc_history_test.append(test_accuracy)\n",
        "\n",
        "\n",
        "        print('Epoch {0}, Train loss {1}, Train Accuracy {2}, Test loss {3}, Test Accuracy {4}'.format(\n",
        "            epoch, train_loss, train_accuracy, test_loss, test_accuracy))\n",
        "\n",
        "    # plotting the Test/Train accuracy vs Epoch\n",
        "    def plot_graphs_accuracy(train_accuracy=[], test_accuracy=[]):\n",
        "        plt.plot(acc_history_train)\n",
        "        plt.plot(acc_history_test)\n",
        "        max_acc_test = max(acc_history_test)\n",
        "        max_accuracy_test_index = acc_history_test.index(max_acc_test)\n",
        "        plt.plot(max_accuracy_test_index, max_acc_test, '.')\n",
        "        plt.text(max_accuracy_test_index, max_acc_test, \" Max Accuracy = {0}\".format(\n",
        "        max_acc_test))\n",
        "        plt.legend([\"train\", \"test\"])\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    # plotting the Test/Train losses vs Epoch\n",
        "    def plot_graphs_losses(train_loss_history=[], test_loss_history=[]):\n",
        "\n",
        "        plt.plot(train_loss_history)\n",
        "        plt.plot(test_loss_history)\n",
        "        plt.legend([\"train\", \"test\"])\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.title('Test/Train Loss Vs Epoch')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    #calling both the above plotting functions    \n",
        "    plot_graphs_accuracy(train_accuracy=acc_history_train,test_accuracy=acc_history_test)\n",
        "    plot_graphs_losses(train_loss_history=train_loss_history, test_loss_history=test_loss_history)\n",
        "\n",
        "\n",
        "    # Calculating the number parameters\n",
        "    def count_parameters(model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print('The Number of Parameters are: {0}'.format(count_parameters(net)))\n",
        "\n",
        "    # saving the weights in .pt file\n",
        "    model_path = './project1_model.pt'\n",
        "    torch.save(net.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project1_model()"
      ],
      "metadata": {
        "id": "ss5OZ15vFrbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}